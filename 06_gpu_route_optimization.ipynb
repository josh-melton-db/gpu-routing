{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e862297-c644-465b-8b3b-d2abe1277225",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install CuOpt"
    }
   },
   "outputs": [],
   "source": [
    "%pip install -q --extra-index-url=https://pypi.nvidia.com cuopt-server-cu12 cuopt-sh-client cuopt-cu12==25.8.*\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "835a1815-de23-48b9-824b-0a17ca51ea4f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Set Configs"
    }
   },
   "outputs": [],
   "source": [
    "NUM_SHIPMENTS = 20_000\n",
    "NUM_ROUTES = int(round(NUM_SHIPMENTS / 250 )) # total trucks available\n",
    "MAX_EV = 4000 # max capacity\n",
    "MAX_VAN = 8000\n",
    "DEPOT_LAT, DEPOT_LON = 39.7685, -86.1580 # start and end point for each route\n",
    "SOLVER_MINUTES = 10\n",
    "\n",
    "\n",
    "catalog = \"default\"\n",
    "schema = f\"routing\"\n",
    "shipments_table = f\"{catalog}.{schema}.raw_shipments_{NUM_SHIPMENTS}\"\n",
    "mapping_table = f\"{catalog}.{schema}.shipment_ids_map_{NUM_SHIPMENTS}\"\n",
    "clustered_table = f\"{catalog}.{schema}.shipment_clusters_gpu_{NUM_SHIPMENTS}\"\n",
    "distances_table = f\"{catalog}.{schema}.distances_by_route_gpu_{NUM_SHIPMENTS}\"\n",
    "routing_table = f\"{catalog}.{schema}.routing_unified_by_cluster_gpu_{NUM_SHIPMENTS}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fa9a5c1-06dd-469f-b92f-3985dd31486f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Check GPU"
    }
   },
   "outputs": [],
   "source": [
    "%sh nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cd04618-1a88-4512-884a-3e00ec5c844c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Import Libraries"
    }
   },
   "outputs": [],
   "source": [
    "import cudf\n",
    "from cuopt import routing, distance_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3abf097b-4a69-4786-bcd9-57ede27591f6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Simple Example"
    }
   },
   "outputs": [],
   "source": [
    "cost = cudf.DataFrame([[0,3,1,2],[3,0,1,2],[2,3,0,2],[2,3,1,0]], dtype='float32')\n",
    "n_locations = cost.shape[0]\n",
    "n_vehicles = 2\n",
    "n_orders = 3  # one order per task node\n",
    "\n",
    "dm = routing.DataModel(n_locations, n_vehicles, n_orders)\n",
    "dm.add_cost_matrix(cost)\n",
    "dm.add_transit_time_matrix(cost.copy(deep=True))  # separate if times differ\n",
    "\n",
    "ss = routing.SolverSettings()\n",
    "ss.set_verbose_mode(True)\n",
    "# ss.set_time_limit(5)\n",
    "sol = routing.Solve(dm, ss)\n",
    "\n",
    "print(sol.get_route())      # pandas-like table\n",
    "sol.display_routes()        # pretty print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29af4d8a-7b91-495a-aac1-413195065d34",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Simple Waypoint Example"
    }
   },
   "outputs": [],
   "source": [
    "# Hello World: cuOpt with CSR Waypoint Graph (no dense N×N)\n",
    "\n",
    "import numpy as np\n",
    "import cudf\n",
    "from cuopt import distance_engine, routing\n",
    "\n",
    "\n",
    "base = np.array([\n",
    "    [0,3,1,2],\n",
    "    [3,0,1,2],\n",
    "    [2,3,0,2],\n",
    "    [2,3,1,0]\n",
    "], dtype=np.float32)\n",
    "\n",
    "V = base.shape[0]\n",
    "# Build CSR: for each src i, edges to all j != i\n",
    "indices = []\n",
    "weights = []\n",
    "offsets = [0]\n",
    "for i in range(V):\n",
    "    for j in range(V):\n",
    "        if i == j:\n",
    "            continue\n",
    "        indices.append(j)\n",
    "        weights.append(float(base[i, j]))\n",
    "    offsets.append(len(indices))\n",
    "\n",
    "indices = np.asarray(indices, dtype=np.int32)        # size E = 12\n",
    "weights = np.asarray(weights, dtype=np.float32)      # size E\n",
    "offsets = np.asarray(offsets, dtype=np.int32)        # size V+1\n",
    "\n",
    "# ----- 2) Build Waypoint graph and compute compact matrix for targets -----\n",
    "wg = distance_engine.WaypointMatrix(offsets, indices, weights)\n",
    "targets = np.arange(V, dtype=np.int32)               # use all 4 nodes; 0 will be the depot\n",
    "cost = wg.compute_cost_matrix(targets)               # cudf.DataFrame (4x4)\n",
    "\n",
    "# ----- 3) Build a minimal routing model and solve -----\n",
    "n_locations = len(targets)\n",
    "n_vehicles  = 2\n",
    "n_orders    = 3\n",
    "\n",
    "dm = routing.DataModel(n_locations, n_vehicles, n_orders)\n",
    "\n",
    "# vehicles start/end at depot (index 0 in our target set)\n",
    "dm.set_vehicle_locations(\n",
    "    cudf.Series([0]*n_vehicles),   # starts\n",
    "    cudf.Series([0]*n_vehicles)    # ends\n",
    ")\n",
    "\n",
    "# 3 orders at locations 1,2,3  (indices within the compact matrix)\n",
    "dm.set_order_locations(cudf.Series([1,2,3]))\n",
    "\n",
    "# Primary matrices\n",
    "dm.add_cost_matrix(cost)\n",
    "\n",
    "# Optional: require both vehicles to be used (just to see multiple routes)\n",
    "dm.set_min_vehicles(n_vehicles)\n",
    "\n",
    "ss = routing.SolverSettings()\n",
    "ss.set_verbose_mode(True)\n",
    "# ss.set_time_limit(5)  # optional\n",
    "\n",
    "sol = routing.Solve(dm, ss)\n",
    "print(sol.get_route())   # pandas-like table\n",
    "sol.display_routes()     # pretty print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0d0bdff-1910-4114-8991-de3a74889d04",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Prepare Data"
    }
   },
   "outputs": [],
   "source": [
    "DEPOT_ID = 0\n",
    "\n",
    "distances_df = (\n",
    "  spark.read.table(distances_table)\n",
    "  .select(\"global_idx_source\", \"global_idx_dest\", \"duration_seconds\")\n",
    ")\n",
    "\n",
    "rev_to_depot = (\n",
    "    distances_df\n",
    "      .where(F.col(\"global_idx_dest\") == DEPOT_ID)\n",
    "      .select(\n",
    "          F.lit(DEPOT_ID).alias(\"global_idx_source\"),\n",
    "          F.col(\"global_idx_source\").alias(\"global_idx_dest\"),\n",
    "          F.col(\"duration_seconds\")\n",
    "      )\n",
    ")\n",
    "\n",
    "distances_df = (\n",
    "    distances_df\n",
    "    .unionByName(rev_to_depot)\n",
    "    # .orderBy(\"global_idx_source\", \"global_idx_dest\")\n",
    ")  \n",
    "display(distances_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0604277-cedd-4c3f-bbe5-33a3d63cd3ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Questions**\n",
    "- Works for 20k packages on a 1 min solver time limit, but do longer solves take more memory?\n",
    "- How do we set a max duration per truck?\n",
    "\n",
    "**Notes**\n",
    "- OOMs at 40k packages\n",
    "- TODO: runs trials on CPU vs GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41f5fbbb-3821-4f2a-96fd-15b17aebe95e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Solve!"
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 1) Pull edges and normalize\n",
    "# ---------------------------\n",
    "pdf = (\n",
    "    distances_df\n",
    "      .select(\"global_idx_source\",\"global_idx_dest\",\"duration_seconds\")\n",
    "      .toPandas()\n",
    ")\n",
    "\n",
    "# Build stable 0..n-1 index space for ALL nodes seen in src or dest\n",
    "all_nodes = pd.Index(pd.unique(pd.concat([pdf[\"global_idx_source\"],\n",
    "                                          pdf[\"global_idx_dest\"]], ignore_index=True)))\n",
    "node2pos = {int(g): i for i, g in enumerate(all_nodes)}\n",
    "n = len(all_nodes)\n",
    "\n",
    "pdf[\"src_idx\"] = pdf[\"global_idx_source\"].map(node2pos).astype(np.int32)\n",
    "pdf[\"dst_idx\"] = pdf[\"global_idx_dest\"].map(node2pos).astype(np.int32)\n",
    "pdf[\"cost\"]    = pdf[\"duration_seconds\"].astype(np.float32)\n",
    "\n",
    "# ---------------------------\n",
    "# 2) Build CSR (offsets/indices/weights)\n",
    "# ---------------------------\n",
    "pdf = pdf.sort_values([\"src_idx\",\"dst_idx\"], kind=\"mergesort\")\n",
    "\n",
    "indices = pdf[\"dst_idx\"].to_numpy(dtype=np.int32)       # E-length array of neighbor dsts\n",
    "weights = pdf[\"cost\"].to_numpy(dtype=np.float32)        # E-length array of edge costs\n",
    "\n",
    "# counts per src over the FULL 0..n-1 range (nodes with 0 out-edges still get an offset)\n",
    "counts = (\n",
    "    pdf.groupby(\"src_idx\").size()\n",
    "       .reindex(range(n), fill_value=0)\n",
    "       .to_numpy(dtype=np.int32)\n",
    ")\n",
    "\n",
    "# offsets[v]..offsets[v+1]-1 slice into `indices`/`weights`\n",
    "offsets = np.concatenate([[0], np.cumsum(counts, dtype=np.int64)]).astype(np.int32)\n",
    "\n",
    "# ---------------------------\n",
    "# 3) Waypoint graph + compact matrix for selected targets\n",
    "# ---------------------------\n",
    "wg = distance_engine.WaypointMatrix(offsets, indices, weights)\n",
    "order_globals = [int(x) for x in all_nodes if int(x) != DEPOT_ID]\n",
    "\n",
    "# Targets are the nodes we want in the compact matrix: [depot] + orders\n",
    "targets = np.array(\n",
    "    [node2pos[DEPOT_ID]] + [node2pos[g] for g in order_globals],\n",
    "    dtype=np.int32\n",
    ")\n",
    "\n",
    "cost = wg.compute_cost_matrix(targets)   # cudf.DataFrame (len(targets) x len(targets))\n",
    "time = cost.copy(deep=True)              # use cost as time for now\n",
    "\n",
    "# ---------------------------\n",
    "# 4) Routing model and solve\n",
    "# ---------------------------\n",
    "n_locations = len(targets)\n",
    "n_orders    = len(order_globals)\n",
    "\n",
    "dm = routing.DataModel(n_locations, NUM_ROUTES, n_orders)\n",
    "dm.set_vehicle_locations(cudf.Series([0]*NUM_ROUTES), cudf.Series([0]*NUM_ROUTES))\n",
    "dm.set_order_locations(cudf.Series(np.arange(1, n_locations, dtype=np.int32)))\n",
    "\n",
    "# Primary matrices\n",
    "dm.add_cost_matrix(cost)\n",
    "dm.add_transit_time_matrix(time)\n",
    "dm.set_min_vehicles(NUM_ROUTES)\n",
    "\n",
    "ss = routing.SolverSettings()\n",
    "ss.set_verbose_mode(True)\n",
    "ss.set_time_limit(SOLVER_MINUTES * 60)  # time limit in seconds\n",
    "\n",
    "sol = routing.Solve(dm, ss)\n",
    "sol.display_routes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce0ddf94-9d17-4a27-942a-e900e4b75d55",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Save Results"
    }
   },
   "outputs": [],
   "source": [
    "route_pdf = sol.get_route().to_pandas()\n",
    "optimized_routes_df = spark.createDataFrame(route_pdf)\n",
    "optimized_routes_df.write.mode(\"overwrite\").saveAsTable(routing_table)\n",
    "display(spark.read.table(routing_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85b40cb4-cf78-4100-aaf1-e6c6aae0c85c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# assert targets[0] == node2pos[DEPOT_ID]       # depot is first\n",
    "# assert n_orders == (len(targets) - 1)         # one order per non-depot target\n",
    "# cm = cost.to_pandas().to_numpy()\n",
    "# unreachable = ~np.isfinite(cm)\n",
    "# print(\"Unreachable pairs:\", np.argwhere(unreachable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e10e26fd-19b2-4334-b2a3-5b36c9d3defc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# order_global_ids = [int(g) for g in all_nodes if int(g) != DEPOT_ID]\n",
    "\n",
    "# # (B) Or: if you have a specific set of task nodes (global ids)\n",
    "# # order_global_ids = my_tasks_global_ids   # e.g., from a Spark/Pandas table\n",
    "\n",
    "# # Build compact target list: depot first, then exactly the order nodes you want\n",
    "# targets = np.array(\n",
    "#     [node2pos[DEPOT_ID]] + [node2pos[g] for g in order_global_ids],\n",
    "#     dtype=np.int32\n",
    "# )\n",
    "\n",
    "# # Compute the compact cost/time matrices over just these targets\n",
    "# cost = wg.compute_cost_matrix(targets)    # cudf.DataFrame\n",
    "# time = cost.copy(deep=True)               # or a different matrix if you have it\n",
    "\n",
    "# # -----------------------------\n",
    "# # Map orders to compact indices\n",
    "# # -----------------------------\n",
    "# # The compact matrix rows/cols are 0..len(targets)-1 with depot at 0\n",
    "# # If there is exactly ONE order per target (typical VRP), orders = [1..n_locations-1]\n",
    "# n_locations = len(targets)\n",
    "# order_locs_compact = np.arange(1, n_locations, dtype=np.int32)\n",
    "\n",
    "# # (C) Multiple orders at the same physical location?\n",
    "# # Suppose you have a table with counts per location; repeat that compact index.\n",
    "# # Example: {global_id: count}\n",
    "# # counts_by_global = {4150: 2, 2766: 1, 958: 3, ...}\n",
    "# # order_locs_compact = []\n",
    "# # for g, cnt in counts_by_global.items():\n",
    "# #     compact_idx = 1 + order_global_ids.index(g)   # because depot is at 0\n",
    "# #     order_locs_compact.extend([compact_idx] * cnt)\n",
    "# # order_locs_compact = np.array(order_locs_compact, dtype=np.int32)\n",
    "\n",
    "# # -----------------------------\n",
    "# # Build and solve the model\n",
    "# # -----------------------------\n",
    "# n_orders   = len(order_locs_compact)\n",
    "# n_vehicles = NUM_ROUTES\n",
    "\n",
    "# dm = routing.DataModel(n_locations, n_vehicles, n_orders)\n",
    "\n",
    "# # Vehicles start/end at depot (compact index 0)\n",
    "# dm.set_vehicle_locations(\n",
    "#     cudf.Series([0]*n_vehicles), \n",
    "#     cudf.Series([0]*n_vehicles)\n",
    "# )\n",
    "\n",
    "# # Tell cuOpt where each order lives (indices into the compact matrix)\n",
    "# dm.set_order_locations(cudf.Series(order_locs_compact))\n",
    "\n",
    "# # Add matrices\n",
    "# dm.add_cost_matrix(cost)\n",
    "# dm.add_transit_time_matrix(time)\n",
    "\n",
    "# # Optional knobs:\n",
    "# # dm.set_min_vehicles(n_vehicles)          # force using all vehicles\n",
    "# # dm.set_vehicle_max_time(cudf.Series([...]))  # cap per-vehicle time to spread work\n",
    "# # dm.set_vehicle_fixed_cost(cudf.Series([...]))# make extra vehicles “cost” something\n",
    "\n",
    "# ss = routing.SolverSettings()\n",
    "# ss.set_verbose_mode(True)\n",
    "# ss.set_time_limit(60)\n",
    "\n",
    "# sol = routing.Solve(dm, ss)\n",
    "# sol.display_routes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54cd8c42-8dce-4383-b7ba-4df1004bdb30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # neighbors_df: columns [src_idx:int, dst_idx:int, cost:float32], ~50 per src\n",
    "# # 1) CSR (offsets/indices/weights) of size V=n, E=edges\n",
    "# n = n_locations\n",
    "# edges = distances_pdf.sort_values([\"global_idx_source\",\"global_idx_dest\"])\n",
    "# indices = edges[\"global_idx_source\"].to_numpy(dtype=np.int32)\n",
    "# weights = edges[\"duration_seconds\"].to_numpy(dtype=np.float32)\n",
    "\n",
    "# # offsets: length n+1; offsets[v]..offsets[v+1]-1 slice into `indices`\n",
    "# counts = edges.groupby(\"global_idx_source\").size().reindex(range(n), fill_value=0).to_numpy(np.int32)\n",
    "# offsets = np.concatenate([[0], np.cumsum(counts)])\n",
    "\n",
    "# all_nodes = pd.concat([distances_pdf[\"global_idx_source\"], distances_pdf[\"global_idx_dest\"]]).unique()\n",
    "# cluster_node_indices = sorted(all_nodes) \n",
    "\n",
    "# # 2) Build WaypointMatrix and compute a dense cost matrix only for a subset\n",
    "# wmat = distance_engine.WaypointMatrix(offsets, indices, weights)\n",
    "# targets = np.array(cluster_node_indices, dtype=np.int32)          # e.g., a 1–5k node cluster + depot\n",
    "# cost_mat = wmat.compute_cost_matrix(targets)                      # returns cudf.DataFrame (float32)\n",
    "\n",
    "# dm = routing.DataModel(cost_mat.shape[0], NUM_ROUTES, max(cost_mat.shape[0]-1, 0))\n",
    "# dm.add_cost_matrix(cost_mat)  # or dm.add_cost_matrix(cost_mat) depending on version\n",
    "\n",
    "# # 3) Solve and save results\n",
    "# ss = routing.SolverSettings()\n",
    "# ss.set_time_limit(60*20)  # time limit in seconds\n",
    "# sol = routing.Solve(dm, ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "557b3790-a32b-49ca-a26b-8b61b811330a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# route_pdf = sol.get_route().to_pandas()\n",
    "# optimized_routes_df = spark.createDataFrame(route_pdf)\n",
    "# optimized_routes_df.write.saveAsTable(routing_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "083c513a-62a3-4814-9e4c-a43192ddde1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # distances_pdf has columns: [global_idx_source, global_idx_dest, duration_seconds]\n",
    "# # Build a stable global index space 0..n-1\n",
    "# all_nodes = pd.Index(\n",
    "#     pd.unique(\n",
    "#         pd.concat([distances_pdf[\"global_idx_source\"], \n",
    "#                    distances_pdf[\"global_idx_dest\"]], \n",
    "#                   ignore_index=True)\n",
    "#     )\n",
    "# )\n",
    "# node2pos = {int(g): i for i, g in enumerate(all_nodes)}\n",
    "# n = len(all_nodes)\n",
    "\n",
    "# # Map to 0-based indices for CSR\n",
    "# edges = distances_pdf[[\"global_idx_source\",\"global_idx_dest\",\"duration_seconds\"]].copy()\n",
    "# edges[\"src_idx\"] = edges[\"global_idx_source\"].map(node2pos).astype(np.int32)\n",
    "# edges[\"dst_idx\"] = edges[\"global_idx_dest\"].map(node2pos).astype(np.int32)\n",
    "# edges[\"cost\"]    = edges[\"duration_seconds\"].astype(np.float32)\n",
    "\n",
    "# # Sort by source, then destination (helps CSR construction)\n",
    "# edges = edges.sort_values([\"src_idx\",\"dst_idx\"], kind=\"mergesort\")\n",
    "\n",
    "# # CSR pieces\n",
    "# indices = edges[\"dst_idx\"].to_numpy(dtype=np.int32)        # DESTINATIONS go here\n",
    "# weights = edges[\"cost\"].to_numpy(dtype=np.float32)         # Edge weights\n",
    "\n",
    "# # counts per source (include sources with zero neighbors)\n",
    "# counts = (\n",
    "#     edges.groupby(\"src_idx\")\n",
    "#          .size()\n",
    "#          .reindex(range(n), fill_value=0)\n",
    "#          .to_numpy(dtype=np.int32)\n",
    "# )\n",
    "# offsets = np.concatenate([[0], np.cumsum(counts)]).astype(np.int32)  # length n+1\n",
    "\n",
    "# # Build waypoint graph\n",
    "# wmat = routing.WaypointMatrix(offsets, indices, weights)\n",
    "\n",
    "# # Choose targets (must be in same 0..n-1 space). Example: cluster_node_indices are your global_idx values.\n",
    "# # Map them to positions; also put depot first if you have a known depot global_idx\n",
    "# targets_pos = np.array([node2pos[int(g)] for g in cluster_node_indices], dtype=np.int32)\n",
    "\n",
    "# # Compute dense cost matrix ONLY for this subset\n",
    "# cost_mat = wmat.compute_cost_matrix(targets_pos)  # cudf.DataFrame (float32), shape k x k\n",
    "\n",
    "# # Solve on the subset\n",
    "# k = cost_mat.shape[0]\n",
    "# dm = routing.DataModel(k, NUM_ROUTES, max(k-1, 0))\n",
    "# # Depending on version: set_matrix or add_cost_matrix\n",
    "# try:\n",
    "#     dm.set_matrix(cost_mat)\n",
    "# except AttributeError:\n",
    "#     dm.add_cost_matrix(cost_mat)\n",
    "\n",
    "# ss = routing.SolverSettings()\n",
    "# ss.set_time_limit(60*20)\n",
    "# sol = routing.Solve(dm, ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88f6e590-dd83-4673-b552-b11c7fc1fc86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # === Build a cuOpt-ready cost matrix from distances_df (cost = duration_seconds) ===\n",
    "# # 1) Get the node list (deterministic order)\n",
    "# nodes = (\n",
    "#     distances_df\n",
    "#       .select(F.col(\"global_idx_source\").alias(\"id\"))\n",
    "#       .unionByName(distances_df.select(F.col(\"global_idx_dest\").alias(\"id\")))\n",
    "#       .distinct()\n",
    "#       .orderBy(\"id\")\n",
    "#       .toPandas()[\"id\"]\n",
    "#       .tolist()\n",
    "# )\n",
    "\n",
    "# # If you have a known depot global index, put it first:\n",
    "# nodes.sort(key=lambda x: (x != 0, x))\n",
    "\n",
    "# n = len(nodes)\n",
    "# idx_pos = {g:i for i,g in enumerate(nodes)}\n",
    "\n",
    "# # 2) Initialize matrix with a big finite penalty; 0 on diagonal\n",
    "# M = np.full((n, n), 1e9, dtype=np.float32)\n",
    "# np.fill_diagonal(M, 0.0)\n",
    "\n",
    "# # 3) Fill matrix from the distances table\n",
    "# pdf = (\n",
    "#     distances_df\n",
    "#       .select(\"global_idx_source\", \"global_idx_dest\", F.col(\"duration_seconds\").alias(\"cost\"))\n",
    "#       .toPandas()\n",
    "# )\n",
    "\n",
    "# for s, d, c in pdf.itertuples(index=False):\n",
    "#     i = idx_pos[s]; j = idx_pos[d]\n",
    "#     M[i, j] = np.float32(c)\n",
    "\n",
    "# cost_gdf = cudf.DataFrame(M)\n",
    "\n",
    "# # 4) cuOpt model: cost = distance, reuse as transit time (simple case)\n",
    "# n_locations = n\n",
    "# n_orders = max(n_locations - 1, 0)  # tasks = all non-depot nodes if you use a depot-first convention\n",
    "\n",
    "# dm = routing.DataModel(n_locations, NUM_ROUTES, n_orders)\n",
    "# dm.add_cost_matrix(cost_gdf)\n",
    "# # dm.add_transit_time_matrix(cost_gdf)\n",
    "\n",
    "# ss = routing.SolverSettings()\n",
    "# ss.set_time_limit(60*20)  # time limit in seconds\n",
    "# sol = routing.Solve(dm, ss)\n",
    "\n",
    "# # 5) (Optional) map cuOpt node_index -> your global_idx\n",
    "# route_pdf = sol.get_route().to_pandas()\n",
    "# route_pdf[\"global_idx\"] = route_pdf[\"node_index\"].map(lambda i: nodes[int(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a091a175-f26a-4a60-b905-1f9c7a053026",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# optimized_routes_df = spark.createDataFrame(route_pdf)\n",
    "# optimized_routes_df.write.saveAsTable(routing_table)\n",
    "# spark.read.table(routing_table).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c21f053-8887-421f-b963-7ca6a15cc0a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Map back to your global_idx for readability\n",
    "# route_pdf = sol.get_route().to_pandas()\n",
    "# pos2node = {v:k for k,v in node2pos.items()}\n",
    "# subset_pos2global = {i: int(cluster_node_indices[i]) for i in range(k)}  # target order\n",
    "# route_pdf[\"global_idx\"] = route_pdf[\"node_index\"].map(lambda i: subset_pos2global[int(i)])\n",
    "\n",
    "# optimized_routes_df = spark.createDataFrame(route_pdf)\n",
    "# optimized_routes_df.write.saveAsTable(routing_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d2b296b-90e3-405e-bf99-3514c73ebbc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "\n",
    "&copy; 2025 Databricks, Inc. All rights reserved. The source in this notebook is provided subject to the [Databricks License](https://databricks.com/db-license-source).  All included or referenced third party libraries are subject to the licenses set forth below.\n",
    "\n",
    "| library                | description                                                                                      | license      | source                                                    |\n",
    "|------------------------|--------------------------------------------------------------------------------------------------|--------------|-----------------------------------------------------------|\n",
    "| OSRM Backend Server    | High performance routing engine written in C++14 designed to run on OpenStreetMap data           | BSD 2-Clause \"Simplified\" License | https://github.com/Project-OSRM/osrm-backend              |\n",
    "| osmnx                  | Download, model, analyze, and visualize street networks and other geospatial features from OpenStreetMap in Python | MIT License  | https://github.com/gboeing/osmnx                          |\n",
    "| ortools                | Operations research tools developed at Google for combinatorial optimization                     | Apache License 2.0 | https://github.com/google/or-tools                        |\n",
    "| folium                 | Visualize data in Python on interactive Leaflet.js maps                                          | MIT License  | https://github.com/python-visualization/folium            |\n",
    "| dash                   | Python framework for building analytical web applications and dashboards; built on Flask, React, and Plotly.js | MIT License  | https://github.com/plotly/dash                            |\n",
    "| branca                 | Library for generating complex HTML+JS pages in Python; provides non-map-specific features for folium | MIT License  | https://github.com/python-visualization/branca            |\n",
    "| plotly                 | Open-source Python library for creating interactive, publication-quality charts and graphs        | MIT License  | https://github.com/plotly/plotly.py                       |\n",
    "ray |\tFlexible, high-performance distributed execution framework for scaling Python workflows |\tApache2.0 |\thttps://github.com/ray-project/ray"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8287725918246293,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "06_gpu_route_optimization",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
